{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from missforest.missforest import MissForest\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from graphviz import Digraph\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vertex:\n",
    "    \"\"\"\n",
    "    Vertex class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name: str):\n",
    "        \"\"\"\n",
    "        Constructor for the Vertex class\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.parents = set() # set consisting of Vertex objects that are parents of this vertex\n",
    "        self.children = set() # set consisting of Vertex objects that are children of this vertex\n",
    "\n",
    "class CausalDAG:\n",
    "    \"\"\"\n",
    "    DAG class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vertex_names: list[str], edges: list[(str, str)]) -> None:\n",
    "        \"\"\"\n",
    "        Constructor for the causal DAG class\n",
    "        \"\"\"\n",
    "\n",
    "        self.vertices = {v: Vertex(v) for v in vertex_names} # dictionary mapping vertex names to Vertex objects\n",
    "        self.edges = [] # list of tuples corresponding to edges in the DAG\n",
    "\n",
    "        # loop over and initialize all vertices to have parent-child relations specified by the edges\n",
    "        for parent_name, child_name in edges:\n",
    "            self.edges.append((parent_name, child_name))\n",
    "            # get the corresponding vertex objects\n",
    "            parent_vertex = self.vertices.get(parent_name)\n",
    "            child_vertex = self.vertices.get(child_name)\n",
    "            # add to the parent/child sets\n",
    "            parent_vertex.children.add(child_vertex)\n",
    "            child_vertex.parents.add(parent_vertex)\n",
    "\n",
    "    def get_parents(self, vertex_name: str) -> list[str]:\n",
    "        \"\"\"\n",
    "        Returns a list of names of the parents\n",
    "        \"\"\"\n",
    "        return [p.name for p in self.vertices[vertex_name].parents]\n",
    "\n",
    "    def get_children(self, vertex_name: str) -> list[str]:\n",
    "        \"\"\"\n",
    "        Returns a list of names of the children\n",
    "        \"\"\"\n",
    "        return [c.name for c in self.vertices[vertex_name].children]\n",
    "\n",
    "    def get_neighbors(self, vertex_name: str) -> list[str]:\n",
    "        \"\"\"\n",
    "        Returns a list of names of the neighbors\n",
    "        \"\"\"\n",
    "        return [n.name for n in self.vertices[vertex_name].neighbors]\n",
    "\n",
    "    def get_descendants(self, vertex_name: str) -> list[str]:\n",
    "        \"\"\"\n",
    "        Returns a list of strings corresponding to descendants of the given vertex.\n",
    "        Note by convention, the descendants of a vertex include the vertex itself.\n",
    "        \"\"\"\n",
    "\n",
    "        stack = [vertex_name]\n",
    "        visited = set()\n",
    "\n",
    "        while len(stack) > 0:\n",
    "\n",
    "            v_name = stack.pop()\n",
    "            if v_name in visited:\n",
    "                continue\n",
    "            visited.add(v_name)\n",
    "            stack += self.get_children(v_name)\n",
    "\n",
    "        return list(visited)\n",
    "\n",
    "\n",
    "    def d_separated(self, x_name: str, y_name: str, z_names: list[str]) -> bool:\n",
    "        \"\"\"\n",
    "        Check if X _||_ Y | Z using d-separation\n",
    "        \"\"\"\n",
    "\n",
    "        # implement this\n",
    "        stack = [(x_name, \"up\")]  # Initialize the stack with the starting vertex X going up\n",
    "        visited = set() # Set of vertices that have already been visited\n",
    "\n",
    "        while stack:\n",
    "            vertex, direction = stack.pop()\n",
    "\n",
    "            if (vertex, direction) in visited:\n",
    "                continue  # Skip if the vertex has already been visited\n",
    "\n",
    "            if vertex == y_name:\n",
    "                return False  # If Y is reached, X and Y are not d-separated given Z\n",
    "\n",
    "            visited.add((vertex, direction))\n",
    "\n",
    "            if direction == \"up\" and vertex not in z_names:\n",
    "                for child in self.get_children(vertex):\n",
    "                    stack.append((child, \"down\"))\n",
    "                # If going up and the vertex is not in Z, explore parents\n",
    "                for parent in self.get_parents(vertex):\n",
    "                    stack.append((parent, \"up\"))\n",
    "\n",
    "            elif direction == \"down\":\n",
    "                if vertex not in z_names:\n",
    "                    for child in self.get_children(vertex):\n",
    "                        stack.append((child, \"down\"))\n",
    "                elif any(descendant in z_names for descendant in self.get_descendants(vertex)):\n",
    "                    for parent in self.get_parents(vertex):\n",
    "                        stack.append((parent, \"up\"))\n",
    "\n",
    "        return True  # If the loop completes, X and Y are d-separated given Z\n",
    "\n",
    "    def valid_backdoor_set(self, a_name: str, y_name: str, z_names: list[str]) -> bool:\n",
    "        \"\"\"\n",
    "        Check if Z is a valid backdoor set for computing the effect of A on Y\n",
    "        \"\"\"\n",
    "\n",
    "        # Check the descendant condition\n",
    "        descendants_a = self.get_descendants(a_name)\n",
    "        for descendant in descendants_a:\n",
    "          if descendant in z_names:\n",
    "            return False  # Z contains descendants of A\n",
    "\n",
    "        # Create a new CausalDAG object with omitted edges A → C for all C ∈ ChG(A)\n",
    "        modified_dag_edges = [(parent, child) for parent, child in self.edges if parent != a_name]\n",
    "        modified_dag = CausalDAG(list(self.vertices.keys()), modified_dag_edges)\n",
    "\n",
    "        # Check the d-separation condition in the modified DAG\n",
    "        if not modified_dag.d_separated(a_name, y_name, z_names):\n",
    "            return False  # A is not d-separated from Y given Z in the modified DAG\n",
    "        return True  # Z is a valid backdoor set\n",
    "\n",
    "\n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Method for visualizing the DAG\n",
    "        \"\"\"\n",
    "\n",
    "        dot = Digraph()\n",
    "        dot.graph_attr[\"rankdir\"] = \"LR\"\n",
    "\n",
    "        for v_name in self.vertices:\n",
    "            dot.node(\n",
    "                v_name,\n",
    "                shape=\"plaintext\",\n",
    "                height=\".5\",\n",
    "                width=\".5\",\n",
    "            )\n",
    "\n",
    "        for parent, child in self.edges:\n",
    "            dot.edge(parent, child, color=\"blue\")\n",
    "\n",
    "        return dot\n",
    "\n",
    "\n",
    "def backdoor_adjustment(data: pd.DataFrame, a_name: str, y_name: str, z_names: list[str]) -> float:\n",
    "    \"\"\"\n",
    "    Perform backdoor adjustment for a given treatment A and outcome Y using\n",
    "    the covariates in Z\n",
    "    \"\"\"\n",
    "\n",
    "    # implement this\n",
    "    z_names = [\"1\"] + z_names\n",
    "    z_formula = \" + \".join(z_names)\n",
    "    regression_formula = f\"{y_name} ~ {z_formula} + {a_name}\"\n",
    "\n",
    "    # fit a regression depending on whether Y is binary or not\n",
    "    if set(data[y_name]) == {0, 1}:\n",
    "        model = smf.glm(formula=regression_formula, family=sm.families.Binomial(), data=data).fit()\n",
    "    else:\n",
    "        model = smf.glm(formula=regression_formula, family=sm.families.Gaussian(), data=data).fit()\n",
    "\n",
    "    data_a1 = data.copy()\n",
    "    data_a1[a_name] = 1\n",
    "    data_a0 = data.copy()\n",
    "    data_a0[a_name] = 0\n",
    "\n",
    "    return round(np.mean(model.predict(data_a1) - model.predict(data_a0)), 3)\n",
    "\n",
    "\n",
    "def compute_confidence_intervals(data: pd.DataFrame, a_name: str, y_name: str, z_names: list[str],\n",
    "                                 num_bootstraps: int=200, alpha: float=0.05) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Compute confidence intervals for backdoor adjustment via bootstrap\n",
    "\n",
    "    Returns tuple (q_low, q_up) for the lower and upper quantiles of the confidence interval.\n",
    "    \"\"\"\n",
    "\n",
    "    Ql = alpha / 2\n",
    "    Qu = 1 - alpha / 2\n",
    "    estimates = []\n",
    "\n",
    "    for i in range(num_bootstraps):\n",
    "\n",
    "        # resample the data with replacement\n",
    "        data_sampled = data.sample(len(data), replace=True)\n",
    "        data_sampled.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # add estimate from resampled data\n",
    "        estimates.append(backdoor_adjustment(data_sampled, a_name, y_name, z_names))\n",
    "\n",
    "    # calculate the quantiles\n",
    "    quantiles = np.quantile(estimates, q=[Ql, Qu])\n",
    "    q_low = quantiles[0]\n",
    "    q_up = quantiles[1]\n",
    "\n",
    "    return round(q_low, 3), round(q_up, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findProperCausalPath(G, X, Y):\n",
    "    \"\"\"\n",
    "    Returns all proper causal paths from the treatment X to outcome Y\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    def dfs(current_vertex, path):\n",
    "        path.append(current_vertex.name)\n",
    "        if current_vertex.name == Y:\n",
    "            result.append(path[:])\n",
    "        else:\n",
    "            for child in current_vertex.children:\n",
    "                dfs(child, path)\n",
    "        path.pop()  # backtrack\n",
    "\n",
    "    source_vertex = G.vertices.get(X)\n",
    "    if source_vertex:\n",
    "        dfs(source_vertex, [])\n",
    "\n",
    "    # Change format of path representation\n",
    "    newPath = []\n",
    "    for path in result:\n",
    "        currPath = []\n",
    "        for i in range(0, len(path) - 1):\n",
    "            currPath.append((path[i], path[i + 1]))\n",
    "        newPath.append(currPath)\n",
    "    return newPath\n",
    "\n",
    "\n",
    "def properBackdoorGraph(G, paths):\n",
    "    \"\"\"\n",
    "    Returns a directed graph G after removing the first edge of every proper causal paths from X to Y.\n",
    "    \"\"\"\n",
    "\n",
    "    edges_to_remove = [path[0] for path in paths if path]\n",
    "    modified_edges = []\n",
    "    for edge in G.edges:\n",
    "        if edge not in edges_to_remove:\n",
    "            modified_edges += [edge]\n",
    "    # Remove duplicate from a list\n",
    "    modified_edges = list(set(modified_edges))\n",
    "    return CausalDAG(list(G.vertices.keys()), modified_edges)\n",
    "\n",
    "def isAncestor(G, X, R_W):\n",
    "    \"\"\"\n",
    "    Returns True if X is an ancestor of any of the variables in list R_W and False otherwise.\n",
    "    \"\"\"\n",
    "    for vertex in R_W:\n",
    "        stack = [vertex]\n",
    "        while len(stack) > 0:\n",
    "            curVertex = stack.pop()\n",
    "            if curVertex == X:\n",
    "                return True\n",
    "            for parent in G.get_parents(curVertex):\n",
    "                    stack.append(parent)\n",
    "\n",
    "    return False\n",
    "\n",
    "def findGXBarBelow(G, X):\n",
    "    \"\"\"\n",
    "    This function returns a directed graph where all outgoing edges from X are deleted.\n",
    "    \"\"\"\n",
    "    # copy a graph G\n",
    "    modified_dag_edges = [(parent, child) for parent, child in G.edges if parent != X]\n",
    "    modified_dag = CausalDAG(list(G.vertices.keys()), modified_dag_edges)\n",
    "    return modified_dag\n",
    "\n",
    "def findGXBarAbove(G, X):\n",
    "    \"\"\"\n",
    "    This function returns a directed graph where all incoming edges to X are deleted.\n",
    "    \"\"\"\n",
    "    modified_dag_edges = [(parent, child) for parent, child in G.edges if child != X]\n",
    "    modified_dag = CausalDAG(list(G.vertices.keys()), modified_dag_edges)\n",
    "    return modified_dag\n",
    "\n",
    "def descend_pcp(G, X, Y):\n",
    "    \"\"\"\n",
    "    Returns descendants of variables in the proper causal paths from X to Y.\n",
    "    \"\"\"\n",
    "    D_pcp = set()\n",
    "    properCausalPaths = findProperCausalPath(G, X, Y)\n",
    "    for path in properCausalPaths:\n",
    "        for edge in path:\n",
    "            for vertex in edge:\n",
    "                descendants = G.get_descendants(vertex)\n",
    "                for var in descendants:\n",
    "                    D_pcp.add(var)\n",
    "    return D_pcp\n",
    "\n",
    "def valid_MAdj(G, X: str, Y: str, Z: list[str], V):\n",
    "    \"\"\"\n",
    "    V: a list of tuples that contains information on each variable in the DAG with its corresponding missingness\n",
    "    mechanism. If a variable is fully observed, the second element of the tuple is None.\n",
    "    Returns a bool value, True if the set Z is a valid m-adjustment set and False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    D_pcp = descend_pcp(G, X, Y)\n",
    "    R_W = []\n",
    "    for pair in V:\n",
    "        if pair[1] is not None:\n",
    "            R_W.append(pair[1])\n",
    "\n",
    "    # Condition 1: No vertex in Z should be in D_pcp\n",
    "    if any(vertex in D_pcp for vertex in Z):\n",
    "        return False\n",
    "\n",
    "    # Condition 2: Y is d-separated from X given Z and R_W in the proper backdoor graph of G with respect to X and Y.\n",
    "    properCausalPaths = findProperCausalPath(G, X, Y)\n",
    "    G_pbd = properBackdoorGraph(G, properCausalPaths)\n",
    "    if not G_pbd.d_separated(Y, X, Z + R_W):\n",
    "        return False\n",
    "\n",
    "    # Condition 3: Y and R_W are d-separated given X in G where all incoming edges from X are deleted.\n",
    "    GXBarAbove = findGXBarAbove(G, X)\n",
    "    for R in R_W:\n",
    "        if not GXBarAbove.d_separated(Y, R, [X]):\n",
    "            return False\n",
    "\n",
    "    # Condition 4: If X is an ancestor of any variable in R_W, then it should be d-separated from Y in G where\n",
    "    # all outgoing edges are deleted.\n",
    "    if isAncestor(G, X, R_W):\n",
    "        GXBarBelow = findGXBarBelow(G, X)\n",
    "        if not GXBarBelow.d_separated(X, Y, []):\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "vertices = ['Z2','R_Z1','R_Z2','Z1','X','Y']\n",
    "edges = [('Z2','R_Z1'),('Z2','R_Z2'),('Z2','X'),('X','Y'),('Z1','X'),('Z1','Y')]\n",
    "\n",
    "G_test1 = CausalDAG(vertices, edges)\n",
    "\n",
    "V1 = [('X', None),('Y', None),('Z1', 'R_Z1'),('Z2', 'R_Z2')]\n",
    "\n",
    "print(valid_MAdj(G_test1,\"X\", \"Y\", [\"Z1\"], V1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 1: Does the function valid_MAdj work correctly? Let's try it on figure 3 of the research paper by Saadati and Tian, which has 2 valid m-adjustment sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "vertices = ['Z2','R_Z1','R_Z2','Z1','X','Y']\n",
    "edges = [('Z2','R_Z1'),('Z2','R_Z2'),('Z2','X'),('X','Y'),('Z1','X'),('Z1','Y')]\n",
    "\n",
    "G_test1 = CausalDAG(vertices, edges)\n",
    "\n",
    "nodes = [('X', None),('Y', None),('Z1', 'R_Z1'),('Z2', 'R_Z2')]\n",
    "\n",
    "print(valid_MAdj(G_test1,\"X\", \"Y\", [], nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 2: The following graph has no m-adjustment set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "vert2 = ['X','Y','Z1','R_Z1','Z2']\n",
    "edge2 = [('X','Y'),('Z1','X'),('Z1','Y'),('X','Z2'),('Y','Z2'),('Z2','R_Z1')]\n",
    "\n",
    "nodes2 = [('X', None),('Y', None),('Z1', 'R_Z1'),('Z2', None)]\n",
    "\n",
    "G_test2 = CausalDAG(vert2, edge2)\n",
    "\n",
    "print(valid_MAdj(G_test2,\"X\", \"Y\", [\"Z1\"], nodes2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expit(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3 in Saadati and Tian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Observed: 4.979 (4.915, 5.037)\n",
      "              Y  X        Z1  Z2  R_Z1  R_Z2  Z1_observed  Z2_observed\n",
      "0    -17.174806  1 -1.450948   1     1     1    -1.450948          1.0\n",
      "1     35.051063  1  1.910953   0     0     1     1.909003          0.0\n",
      "2     18.503200  1  0.711879   1     1     1     0.711879          1.0\n",
      "3     -3.302550  0 -0.247738   1     1     1    -0.247738          1.0\n",
      "4      6.903010  0  0.361466   1     1     1     0.361466          1.0\n",
      "...         ... ..       ...  ..   ...   ...          ...          ...\n",
      "4995 -14.560600  1 -1.151231   0     0     0    -1.151284          0.0\n",
      "4996   2.267209  1 -0.178274   0     0     1    -0.178300          0.0\n",
      "4997 -17.788627  0 -1.112340   0     0     0    -1.112089          0.0\n",
      "4998  -0.175470  1 -0.359393   0     0     0    -0.358401          0.0\n",
      "4999 -10.861914  0 -0.665746   1     1     1    -0.665746          1.0\n",
      "\n",
      "[5000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "vertices = ['Z2','R_Z1','R_Z2','Z1','X','Y']\n",
    "edges = [('Z2','R_Z1'),('Z2','R_Z2'),('Z2','X'),('X','Y'),('Z1','X'),('Z1','Y')]\n",
    "\n",
    "G = CausalDAG(vertices, edges)\n",
    "\n",
    "np.random.seed(200)\n",
    "\n",
    "size = 5000\n",
    "Z1 = np.random.normal(0, 1, size)\n",
    "Z2 = np.random.binomial(1, 0.5, size)\n",
    "X = np.random.binomial(1, expit(Z1 + Z2 + Z1 ** 2), size)\n",
    "Y = 15.5 * Z1 + 5 * X + np.random.normal(0, 1, size)\n",
    "\n",
    "data = pd.DataFrame({\"Y\": Y, \"X\": X, \"Z1\": Z1, \"Z2\": Z2})\n",
    "print('Fully Observed:', backdoor_adjustment(data, 'X','Y', ['Z1']), compute_confidence_intervals(data, 'X','Y', ['Z1']))\n",
    "\n",
    "\n",
    "R_Z1 = np.random.binomial(1, expit(Z2 * 5), size)\n",
    "R_Z2 = np.random.binomial(1, expit(Z2 * 3), size)\n",
    "\n",
    "# At least 60% of the data is observed\n",
    "assert R_Z1.sum() >= size * 0.6, 'Invalid'\n",
    "assert R_Z2.sum() >= size * 0.6, 'Invalid'\n",
    "\n",
    "\n",
    "Z1_observed = Z1.copy().astype(float)\n",
    "Z2_observed = Z2.copy().astype(float)\n",
    "\n",
    "# If R_Z1 or R_Z2 is missing, put in -1.\n",
    "for i in range(size):\n",
    "    if R_Z1[i] == 0:\n",
    "        Z1_observed[i] = np.nan\n",
    "    if R_Z2[i] == 0:\n",
    "        Z2_observed[i] = np.nan\n",
    "\n",
    "\n",
    "# Create new data augmented with observed values and missingness mechanisms.\n",
    "new_data = data.copy()\n",
    "new_data[\"R_Z1\"] = R_Z1\n",
    "new_data[\"R_Z2\"] = R_Z2\n",
    "new_data[\"Z1_observed\"] = Z1_observed\n",
    "new_data[\"Z2_observed\"] = Z2_observed\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "rgr = RandomForestRegressor(n_jobs=-1)\n",
    "\n",
    "mf = MissForest(clf, rgr)\n",
    "df_imputed = mf.fit_transform(new_data)\n",
    "print(df_imputed)\n",
    "\n",
    "# Remove rows where values are missing\n",
    "# new_data = new_data[new_data[\"Z1_observed\"] != -1]\n",
    "# new_data = new_data[new_data[\"Z2_observed\"] != -1]\n",
    "\n",
    "\n",
    "# when calculating backdoor_adjustment, we only need to pass in Z1, we don't need R_Z1 since conditioning is implied\n",
    "# print('Missing Data:', backdoor_adjustment(new_data, 'X','Y', ['Z1_observed']), compute_confidence_intervals(new_data, 'X','Y', ['Z1_observed']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 2: Has no valid m-adjustment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Observed: 3.008 (2.978, 3.037)\n",
      "0.5453\n",
      "Missing Data: 2.89 (2.845, 2.935)\n"
     ]
    }
   ],
   "source": [
    "vert2 = ['X','Y','Z1','R_Z1','Z2']\n",
    "edge2 = [('X','Y'),('Z1','X'),('Z1','Y'),('X','Z2'),('Y','Z2'),('Z2','R_Z1')]\n",
    "CausalDAG(vert2, edge2).draw()\n",
    "\n",
    "np.random.seed(200)\n",
    "\n",
    "# data generation\n",
    "size = 20000\n",
    "\n",
    "Z1 = np.random.normal(0, 1, size)\n",
    "X = np.random.binomial(1, expit(2 * Z1 + Z1 ** 2), size)\n",
    "Y = 2 + 2 * Z1 + 3 * X + np.random.normal(0, 1, size)\n",
    "Z2 = 2 * X + 3 * 3 * Y + np.random.normal(0, 1, size)\n",
    "data = pd.DataFrame({\"Y\": Y, \"X\": X, \"Z1\": Z1, \"Z2\": Z2})\n",
    "print('Fully Observed:', backdoor_adjustment(data, 'X','Y', ['Z1']), compute_confidence_intervals(data, 'X','Y', ['Z1']))\n",
    "\n",
    "\n",
    "R_Z1 = np.random.binomial(1, expit(-0.05 * Z2 + 2), size)\n",
    "print(np.mean(R_Z1))\n",
    "\n",
    "Z1_observed = Z1.copy()\n",
    "for i in range(size):\n",
    "    if R_Z1[i] == 0:\n",
    "        Z1_observed[i] = -1\n",
    "\n",
    "# Create new data augmented with observed values and missingness mechanisms.\n",
    "new_data = data.copy()\n",
    "new_data[\"R_Z1\"] = R_Z1\n",
    "new_data[\"Z1_observed\"] = Z1_observed\n",
    "\n",
    "# Remove rows where Z1 is missing\n",
    "new_data = new_data[new_data[\"Z1_observed\"] != -1]\n",
    "print('Missing Data:', backdoor_adjustment(new_data , 'X','Y', ['Z1_observed']), compute_confidence_intervals(new_data, 'X','Y', ['Z1_observed']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
